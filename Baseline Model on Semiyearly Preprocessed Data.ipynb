{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\"\"\"------------SECTION IMPORTS---------------------\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Define search space for number of trees in random forest and depth of trees\n",
    "num_trees_min = 64\n",
    "num_trees_max = 128\n",
    "\n",
    "depth_min = 2\n",
    "depth_max = 7"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Useful functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Function that returns every possible subset (except the empty set) of the input list l\n",
    "def subsets(l: object) -> object:\n",
    "    subset_list = []\n",
    "    for i in range(len(l) + 1):\n",
    "        for j in range(i):\n",
    "            subset_list.append(l[j: i])\n",
    "    return subset_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import data\n",
    "NaN data needs to be dropped for RF to work\n",
    "1. I drop the columns which have NaN values which is all the new data\n",
    "2. I create a new dataframe which has no columns containing NaN values\n",
    "3. Copy the `next_prevalence` column to this dataframe and once again drop rows containing NaN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "         date   district  prevalence  next_prevalence  prevalence_6lag  \\\n0  2018-01-01      Burco      0.2028         0.221137         0.335941   \n1  2018-01-01      Xudur      0.4862         0.468902         0.486200   \n2  2018-01-01    Bossaso      0.3432         0.482211         0.416056   \n3  2018-01-01     Cadale      0.3510         0.282920         0.369200   \n4  2018-01-01  Qoryooley      0.3510         0.436380         0.369200   \n\n       ndvi   ipc  population  month  district_encoded  increase  \n0  0.185000  0.05  534884.895      1                21      True  \n1  0.248333  0.14  113853.105      1                77     False  \n2  0.148333  0.01  316531.980      1                18      True  \n3  0.226667  0.00   48461.805      1                27     False  \n4  0.346667  0.09  196309.485      1                65      True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>district</th>\n      <th>prevalence</th>\n      <th>next_prevalence</th>\n      <th>prevalence_6lag</th>\n      <th>ndvi</th>\n      <th>ipc</th>\n      <th>population</th>\n      <th>month</th>\n      <th>district_encoded</th>\n      <th>increase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-01-01</td>\n      <td>Burco</td>\n      <td>0.2028</td>\n      <td>0.221137</td>\n      <td>0.335941</td>\n      <td>0.185000</td>\n      <td>0.05</td>\n      <td>534884.895</td>\n      <td>1</td>\n      <td>21</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-01-01</td>\n      <td>Xudur</td>\n      <td>0.4862</td>\n      <td>0.468902</td>\n      <td>0.486200</td>\n      <td>0.248333</td>\n      <td>0.14</td>\n      <td>113853.105</td>\n      <td>1</td>\n      <td>77</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-01-01</td>\n      <td>Bossaso</td>\n      <td>0.3432</td>\n      <td>0.482211</td>\n      <td>0.416056</td>\n      <td>0.148333</td>\n      <td>0.01</td>\n      <td>316531.980</td>\n      <td>1</td>\n      <td>18</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-01-01</td>\n      <td>Cadale</td>\n      <td>0.3510</td>\n      <td>0.282920</td>\n      <td>0.369200</td>\n      <td>0.226667</td>\n      <td>0.00</td>\n      <td>48461.805</td>\n      <td>1</td>\n      <td>27</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-01-01</td>\n      <td>Qoryooley</td>\n      <td>0.3510</td>\n      <td>0.436380</td>\n      <td>0.369200</td>\n      <td>0.346667</td>\n      <td>0.09</td>\n      <td>196309.485</td>\n      <td>1</td>\n      <td>65</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/no_missings_sy.csv\")\n",
    "df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "69"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.district_encoded.unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RF-CV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "'''------------SECTION RANDOM FOREST CROSS VALIDATION--------------'''\n",
    "# WARNING: this process can take some time, since there are a lot of hyperparameters to investigate. The search space can be manually reduced to speed up the process.\n",
    "\n",
    "# Create empty list to store model scores\n",
    "parameter_scores = []\n",
    "\n",
    "# Define target and explanatory variables\n",
    "X = df.select_dtypes(exclude=[\"category\",\"object\"]).drop([\"increase\", \"prevalence\", \"next_prevalence\"],axis=1)\n",
    "y = df['next_prevalence'].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "   prevalence_6lag      ndvi   ipc  population  month  district_encoded\n0         0.335941  0.185000  0.05  534884.895      1                21\n1         0.486200  0.248333  0.14  113853.105      1                77\n2         0.416056  0.148333  0.01  316531.980      1                18\n3         0.369200  0.226667  0.00   48461.805      1                27\n4         0.369200  0.346667  0.09  196309.485      1                65",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prevalence_6lag</th>\n      <th>ndvi</th>\n      <th>ipc</th>\n      <th>population</th>\n      <th>month</th>\n      <th>district_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.335941</td>\n      <td>0.185000</td>\n      <td>0.05</td>\n      <td>534884.895</td>\n      <td>1</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.486200</td>\n      <td>0.248333</td>\n      <td>0.14</td>\n      <td>113853.105</td>\n      <td>1</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.416056</td>\n      <td>0.148333</td>\n      <td>0.01</td>\n      <td>316531.980</td>\n      <td>1</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.369200</td>\n      <td>0.226667</td>\n      <td>0.00</td>\n      <td>48461.805</td>\n      <td>1</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.369200</td>\n      <td>0.346667</td>\n      <td>0.09</td>\n      <td>196309.485</td>\n      <td>1</td>\n      <td>65</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.22113668, 0.4689021 , 0.48221061, 0.28292017, 0.43637985])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train-test split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "array([21, 77, 18, 27, 65,  3, 55, 26, 25, 59, 19, 60, 64, 23, 78, 20, 61,\n       22, 41,  4, 63, 62, 24, 54, 53, 40,  0, 42, 39, 43, 38, 44, 37, 45,\n       36,  1, 46, 35, 47, 34, 48, 33, 49, 32, 50, 31,  2, 51, 30, 52, 29,\n       28, 58, 15, 74, 72, 11, 13, 70, 76, 75, 10, 71,  7, 17,  8, 16, 73,\n       69], dtype=int64)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.district_encoded[:207].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 13/64 [02:55<12:18, 14.48s/it]"
     ]
    }
   ],
   "source": [
    "for num_trees in tqdm(range(num_trees_min, num_trees_max)):\n",
    "\n",
    "    for depth in range(depth_min, depth_max):\n",
    "\n",
    "        # Investigate every subset of explanatory variables\n",
    "        # noinspection PyTypeChecker\n",
    "        for features in subsets(X.columns):\n",
    "            # First CV split. The 207 refers to the first 3 observations for the 69 districts in the data.\n",
    "            #\n",
    "            Xtrain = X[:207][features].copy().values\n",
    "            ytrain = y[:207]\n",
    "            Xtest = X[207:][features].copy().values\n",
    "            ytest = y[207:]\n",
    "\n",
    "            # Create a RandomForestRegressor with the selected hyperparameters and random state 0.\n",
    "            clf = RandomForestRegressor(n_estimators=num_trees, max_depth=depth, random_state=0, n_jobs=-1)\n",
    "\n",
    "            # Fit to the training data\n",
    "            clf.fit(Xtrain, ytrain)\n",
    "\n",
    "            # Make a prediction on the test data\n",
    "            predictions = clf.predict(Xtest)\n",
    "\n",
    "            # Calculate mean absolute error\n",
    "            MAE1 = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "            # Second CV split. The 276 refers to the first 4 observations for the 69 districts in the data.\n",
    "            Xtrain = X[:276][features].copy().values\n",
    "            ytrain = y[:276]\n",
    "            Xtest = X[276:][features].copy().values\n",
    "            ytest = y[276:]\n",
    "\n",
    "            # Create a RandomForestRegressor with the selected hyperparameters and random state 0.\n",
    "            clf = RandomForestRegressor(n_estimators=num_trees, max_depth=depth, random_state=0, n_jobs=-1)\n",
    "\n",
    "            # Fit to the training data\n",
    "            clf.fit(Xtrain, ytrain)\n",
    "\n",
    "            # Make a prediction on the test data\n",
    "            predictions = clf.predict(Xtest)\n",
    "\n",
    "            # Calculate mean absolute error\n",
    "            MAE2 = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "            # Calculate the mean MAE over the two folds\n",
    "            mean_MAE = (MAE1 + MAE2) / 2\n",
    "\n",
    "            # Store the mean MAE together with the used hyperparameters in list\n",
    "            parameter_scores.append((mean_MAE, num_trees, depth, features))\n",
    "\n",
    "# Sort the models based on score and retrieve the hyperparameters of the best model\n",
    "parameter_scores.sort(key=lambda x: x[0])\n",
    "best_model_score = parameter_scores[0][0]\n",
    "best_model_trees = parameter_scores[0][1]\n",
    "best_model_depth = parameter_scores[0][2]\n",
    "best_model_columns = list(parameter_scores[0][3])\n",
    "\n",
    "'''------------SECTION FINAL EVALUATION--------------'''\n",
    "X = df[best_model_columns].values\n",
    "y = df['next_prevalence'].values\n",
    "\n",
    "# If there is only one explanatory variable, the values need to be reshaped for the model\n",
    "if len(best_model_columns) == 1:\n",
    "    X = X.reshape(-1, 1)\n",
    "\n",
    "# Peform evaluation on full data\n",
    "Xtrain = X[:300]\n",
    "ytrain = y[:300]\n",
    "Xtest = X[300:]\n",
    "ytest = y[300:]\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=best_model_trees, max_depth=best_model_depth, random_state=0, n_jobs=-1)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "predictions = clf.predict(Xtest)\n",
    "\n",
    "len(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fix `prevalence` on line 5 in the next code block"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate MAE\n",
    "MAE = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "# Generate boolean values for increase or decrease in prevalence. 0 if next prevalence is smaller than current prevalence, 1 otherwise.\n",
    "increase = [0 if x < y else 1 for x in df['next_prevalence'] for y in df['prevalence']]\n",
    "predicted_increase = [0 if x < y else 1 for x in predictions for y in df['prevalence']]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate accuracy of predicted boolean increase/decrease\n",
    "acc = accuracy_score(increase, predicted_increase)\n",
    "\n",
    "# Print model parameters\n",
    "print('no. of trees: ' + str(best_model_trees) + '\\nmax_depth: ' + str(best_model_depth) + '\\ncolumns: ' + str(\n",
    "    best_model_columns))\n",
    "\n",
    "# Print model scores\n",
    "print(MAE, acc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = 'baseline_semiyearly_model.joblib'\n",
    "joblib.dump(clf, filename)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from helper_metrics import make_confusion_matrix, roc_curve_gen, calculate_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "make_confusion_matrix(increase, predicted_increase,figsize=(6,6),classes=[\"Increase\", \"Decrease\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "roc_curve_gen(increase, predicted_increase)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calculate_results(increase, predicted_increase, average=\"weighted\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
