{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"------------SECTION IMPORTS---------------------\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "\n",
    "'''------------SECTION USER VARIABLES--------------'''\n",
    "# Define the path to your datafolder below\n",
    "your_datapath = '../data/'\n",
    "\n",
    "# Define search space for number of trees in random forest and depth of trees\n",
    "num_trees_min = 64\n",
    "num_trees_max = 128\n",
    "\n",
    "depth_min = 2\n",
    "depth_max = 7"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Useful functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function that returns every possible subset (except the empty set) of the input list l\n",
    "def subsets(l: object) -> object:\n",
    "    subset_list = []\n",
    "    for i in range(len(l) + 1):\n",
    "        for j in range(i):\n",
    "            subset_list.append(l[j: i])\n",
    "    return subset_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import data\n",
    "NaN data needs to be dropped for RF to work\n",
    "1. I drop the columns which have NaN values which is all the new data\n",
    "2. I create a new dataframe which has no columns containing NaN values\n",
    "3. Copy the `next_prevalence` column to this dataframe and once again drop rows containing NaN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/semiyearly_data.csv\")\n",
    "df2 = df.dropna(axis=1)\n",
    "df2[\"next_prevalence\"]= df[\"next_prevalence\"]\n",
    "df2 = df2.dropna(axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Inspect the dtypes of each column\n",
    "df2.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df2.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RF-CV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''------------SECTION RANDOM FOREST CROSS VALIDATION--------------'''\n",
    "# WARNING: this process can take some time, since there are a lot of hyperparameters to investigate. The search space can be manually reduced to speed up the process.\n",
    "\n",
    "# Create empty list to store model scores\n",
    "parameter_scores = []\n",
    "\n",
    "# Define target and explanatory variables\n",
    "X = df.select_dtypes(exclude=[\"category\",\"object\"])\n",
    "y = df['next_prevalence'].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for num_trees in range(num_trees_min, num_trees_max):\n",
    "\n",
    "    for depth in range(depth_min, depth_max):\n",
    "\n",
    "        # Investigate every subset of explanatory variables\n",
    "        # noinspection PyTypeChecker\n",
    "        for features in tqdm(subsets(X.columns)):\n",
    "            # First CV split. The 99 refers to the first 3 observations for the 33 districts in the data.\n",
    "            Xtrain = X[:99][features].copy().values\n",
    "            ytrain = y[:99]\n",
    "            Xtest = X[99:132][features].copy().values\n",
    "            ytest = y[99:132]\n",
    "\n",
    "            # Create a RandomForestRegressor with the selected hyperparameters and random state 0.\n",
    "            clf = RandomForestRegressor(n_estimators=num_trees, max_depth=depth, random_state=0, n_jobs=-1)\n",
    "\n",
    "            # Fit to the training data\n",
    "            clf.fit(Xtrain, ytrain)\n",
    "\n",
    "            # Make a prediction on the test data\n",
    "            predictions = clf.predict(Xtest)\n",
    "\n",
    "            # Calculate mean absolute error\n",
    "            MAE1 = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "            # Second CV split. The 132 refers to the first 4 observations for the 33 districts in the data.\n",
    "            Xtrain = X[:132][features].copy().values\n",
    "            ytrain = y[:132]\n",
    "            Xtest = X[132:165][features].copy().values\n",
    "            ytest = y[132:165]\n",
    "\n",
    "            # Create a RandomForestRegressor with the selected hyperparameters and random state 0.\n",
    "            clf = RandomForestRegressor(n_estimators=num_trees, max_depth=depth, random_state=0, n_jobs=-1)\n",
    "\n",
    "            # Fit to the training data\n",
    "            clf.fit(Xtrain, ytrain)\n",
    "\n",
    "            # Make a prediction on the test data\n",
    "            predictions = clf.predict(Xtest)\n",
    "\n",
    "            # Calculate mean absolute error\n",
    "            MAE2 = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "            # Calculate the mean MAE over the two folds\n",
    "            mean_MAE = (MAE1 + MAE2) / 2\n",
    "\n",
    "            # Store the mean MAE together with the used hyperparameters in list\n",
    "            parameter_scores.append((mean_MAE, num_trees, depth, features))\n",
    "\n",
    "# Sort the models based on score and retrieve the hyperparameters of the best model\n",
    "parameter_scores.sort(key=lambda x: x[0])\n",
    "best_model_score = parameter_scores[0][0]\n",
    "best_model_trees = parameter_scores[0][1]\n",
    "best_model_depth = parameter_scores[0][2]\n",
    "best_model_columns = list(parameter_scores[0][3])\n",
    "\n",
    "'''------------SECTION FINAL EVALUATION--------------'''\n",
    "X = df[best_model_columns].values\n",
    "y = df['next_prevalence'].values\n",
    "\n",
    "# If there is only one explanatory variable, the values need to be reshaped for the model\n",
    "if len(best_model_columns) == 1:\n",
    "    X = X.reshape(-1, 1)\n",
    "\n",
    "# Peform evaluation on full data\n",
    "Xtrain = X[:300]\n",
    "ytrain = y[:300]\n",
    "Xtest = X[300:]\n",
    "ytest = y[300:]\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=best_model_trees, max_depth=best_model_depth, random_state=0, n_jobs=-1)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "predictions = clf.predict(Xtest)\n",
    "\n",
    "len(predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fix `prevalence` on line 5 in the next code block"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate MAE\n",
    "MAE = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "# Generate boolean values for increase or decrease in prevalence. 0 if next prevalence is smaller than current prevalence, 1 otherwise.\n",
    "increase = [0 if x < y else 1 for x in df['next_prevalence'] for y in df['GAM Prevalence']]\n",
    "predicted_increase = [0 if x < y else 1 for x in predictions for y in df['GAM Prevalence']]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate accuracy of predicted boolean increase/decrease\n",
    "acc = accuracy_score(increase, predicted_increase)\n",
    "\n",
    "# Print model parameters\n",
    "print('no. of trees: ' + str(best_model_trees) + '\\nmax_depth: ' + str(best_model_depth) + '\\ncolumns: ' + str(\n",
    "    best_model_columns))\n",
    "\n",
    "# Print model scores\n",
    "print(MAE, acc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = 'baseline_semiyearly_model.joblib'\n",
    "joblib.dump(clf, filename)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from helper_metrics import make_confusion_matrix, roc_curve_gen, calculate_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "make_confusion_matrix(increase, predicted_increase,figsize=(6,6),classes=[\"Increase\", \"Decrease\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "roc_curve_gen(increase, predicted_increase)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calculate_results(increase, predicted_increase, average=\"weighted\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
