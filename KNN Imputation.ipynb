{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0801f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "your_datapath = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f802969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(your_datapath + 'semiyearly_chosen_columns.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb5fc561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE FOR NDVI IMPUTATION IS 0.07084417714884857; SCALE:0 - 0.61\n",
      "RMSE FOR IPC IMPUTATION IS 0.053604531367530205; SCALE 0 - 0.58\n",
      "RMSE FOR PRICE OF WATER IMPUTATION IS 8.726630810199355; SCALE: 2.5 - 100 ish\n",
      "RMSE FOR TOTAL CONFLICT IMPUTATION IS 1.4355538764180065; SCALE 1 - 8 ish\n"
     ]
    }
   ],
   "source": [
    "# drop all rows that have missing values to create a dataset on which\n",
    "# we can test how well the KNN imputation works on the desired columns\n",
    "df_test = df.copy()\n",
    "df_test = df_test.drop(['date', 'district', 'Average of centy', 'Average of centx'], axis = 1)\n",
    "df_test = df_test.dropna(axis = 0)\n",
    "\n",
    "#  we need to normalize the data to make sure the imputer isn't bisaed\n",
    "scaler = MinMaxScaler()\n",
    "df_test_scaled = pd.DataFrame(scaler.fit_transform(df_test), columns = df_test.columns)\n",
    "# print(df_test_scaled.head())\n",
    "\n",
    "# Set seed for reproductibility\n",
    "np.random.seed(18)\n",
    "\n",
    "\n",
    "#################################### NDVI ###########################################################\n",
    "\n",
    "\n",
    "# defining the columns where we wnat to remone some data\n",
    "features = ['ndvi_score']\n",
    "\n",
    "#  Inserting NaN values into Experiment Group\n",
    "for col in df_test_scaled[features]:\n",
    "#     20% of the data will be removed (frac = 0.2)\n",
    "# Rows may be selected more that once (replace = true) - only useful if you have more than one column in features\n",
    "    df_test_scaled.loc[df_test_scaled.sample(frac=0.2, replace=True).index, col] = np.nan\n",
    "# df_test_scaled.info()\n",
    "\n",
    "# Creating a list of indices\n",
    "nan_cols = df_test_scaled[features]\n",
    "nan_cols = nan_cols[nan_cols.isna().any(axis = 1)]\n",
    "null_idx = list(nan_cols.index)\n",
    "\n",
    "# Creating Answer key to compare future results against\n",
    "answer_key = df_test.iloc[null_idx]\n",
    "answer_key\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_test_imputed = pd.DataFrame(imputer.fit_transform(df_test_scaled), columns = df_test_scaled.columns)\n",
    "\n",
    "# Invert scaling\n",
    "inverse_df_test_imputed = pd.DataFrame(scaler.inverse_transform(df_test_imputed), columns = df_test_imputed.columns)\n",
    "\n",
    "# Subsetting data to match that of our answer key\n",
    "test = inverse_df_test_imputed.iloc[null_idx]\n",
    "test.head()\n",
    "\n",
    "# Resetting indexes of test and answer_key for iteration\n",
    "test = test.reset_index()\n",
    "test.drop(['index'], axis = 1, inplace= True)\n",
    "answer_key = answer_key.reset_index()\n",
    "answer_key.drop(['index'], axis = 1, inplace= True)\n",
    "\n",
    "# Calculate results\n",
    "results = pd.DataFrame((round((answer_key - test), 3)))\n",
    "# results.head()\n",
    "\n",
    "# calculate RMSE\n",
    "squared_terms = []\n",
    "for col in results[features]:\n",
    "    for i in range(len(results)):\n",
    "        if results[col][i] != 0.00 or results[col][i] != -0.00:\n",
    "            error = results[col][i]\n",
    "            squared_error = error ** 2\n",
    "            squared_terms.append(squared_error)\n",
    "            \n",
    "num_nan = df_test_scaled.isna().sum().sum()\n",
    "sum_sqr_err = sum(squared_terms)\n",
    "mse = sum_sqr_err/num_nan\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'RMSE FOR NDVI IMPUTATION IS {rmse}; SCALE:0 - 0.61')\n",
    "\n",
    "\n",
    "################################# IPC #############################################\n",
    "\n",
    "\n",
    "# defining the columns where we wnat to remone some data\n",
    "features = ['phase3plus_perc_x']\n",
    "\n",
    "#  Inserting NaN values into Experiment Group\n",
    "for col in df_test_scaled[features]:\n",
    "#     20% of the data will be removed (frac = 0.2)\n",
    "# Rows may be selected more that once (replace = true) - only useful if you have more than one column in features\n",
    "    df_test_scaled.loc[df_test_scaled.sample(frac=0.2, replace=True).index, col] = np.nan\n",
    "# df_test_scaled.info()\n",
    "\n",
    "# Creating a list of indices\n",
    "nan_cols = df_test_scaled[features]\n",
    "nan_cols = nan_cols[nan_cols.isna().any(axis = 1)]\n",
    "null_idx = list(nan_cols.index)\n",
    "\n",
    "# Creating Answer key to compare future results against\n",
    "answer_key = df_test.iloc[null_idx]\n",
    "answer_key\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_test_imputed = pd.DataFrame(imputer.fit_transform(df_test_scaled), columns = df_test_scaled.columns)\n",
    "\n",
    "# Invert scaling\n",
    "inverse_df_test_imputed = pd.DataFrame(scaler.inverse_transform(df_test_imputed), columns = df_test_imputed.columns)\n",
    "\n",
    "# Subsetting data to match that of our answer key\n",
    "test = inverse_df_test_imputed.iloc[null_idx]\n",
    "test.head()\n",
    "\n",
    "# Resetting indexes of test and answer_key for iteration\n",
    "test = test.reset_index()\n",
    "test.drop(['index'], axis = 1, inplace= True)\n",
    "answer_key = answer_key.reset_index()\n",
    "answer_key.drop(['index'], axis = 1, inplace= True)\n",
    "\n",
    "# Calculate results\n",
    "results = pd.DataFrame((round((answer_key - test), 3)))\n",
    "# results.head()\n",
    "\n",
    "# calculate RMSE\n",
    "squared_terms = []\n",
    "for col in results[features]:\n",
    "    for i in range(len(results)):\n",
    "        if results[col][i] != 0.00 or results[col][i] != -0.00:\n",
    "            error = results[col][i]\n",
    "            squared_error = error ** 2\n",
    "            squared_terms.append(squared_error)\n",
    "            \n",
    "num_nan = df_test_scaled.isna().sum().sum()\n",
    "sum_sqr_err = sum(squared_terms)\n",
    "mse = sum_sqr_err/num_nan\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'RMSE FOR IPC IMPUTATION IS {rmse}; SCALE 0 - 0.58')\n",
    "\n",
    "\n",
    "################################## Price of water ################################3\n",
    "\n",
    "\n",
    "# defining the columns where we wnat to remone some data\n",
    "features = ['Price of water']\n",
    "\n",
    "#  Inserting NaN values into Experiment Group\n",
    "for col in df_test_scaled[features]:\n",
    "#     20% of the data will be removed (frac = 0.2)\n",
    "# Rows may be selected more that once (replace = true) - only useful if you have more than one column in features\n",
    "    df_test_scaled.loc[df_test_scaled.sample(frac=0.2, replace=True).index, col] = np.nan\n",
    "# df_test_scaled.info()\n",
    "\n",
    "# Creating a list of indices\n",
    "nan_cols = df_test_scaled[features]\n",
    "nan_cols = nan_cols[nan_cols.isna().any(axis = 1)]\n",
    "null_idx = list(nan_cols.index)\n",
    "\n",
    "# Creating Answer key to compare future results against\n",
    "answer_key = df_test.iloc[null_idx]\n",
    "answer_key\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_test_imputed = pd.DataFrame(imputer.fit_transform(df_test_scaled), columns = df_test_scaled.columns)\n",
    "\n",
    "# Invert scaling\n",
    "inverse_df_test_imputed = pd.DataFrame(scaler.inverse_transform(df_test_imputed), columns = df_test_imputed.columns)\n",
    "\n",
    "# Subsetting data to match that of our answer key\n",
    "test = inverse_df_test_imputed.iloc[null_idx]\n",
    "test.head()\n",
    "\n",
    "# Resetting indexes of test and answer_key for iteration\n",
    "test = test.reset_index()\n",
    "test.drop(['index'], axis = 1, inplace= True)\n",
    "answer_key = answer_key.reset_index()\n",
    "answer_key.drop(['index'], axis = 1, inplace= True)\n",
    "\n",
    "# Calculate results\n",
    "results = pd.DataFrame((round((answer_key - test), 3)))\n",
    "# results.head()\n",
    "\n",
    "# calculate RMSE\n",
    "squared_terms = []\n",
    "for col in results[features]:\n",
    "    for i in range(len(results)):\n",
    "        if results[col][i] != 0.00 or results[col][i] != -0.00:\n",
    "            error = results[col][i]\n",
    "            squared_error = error ** 2\n",
    "            squared_terms.append(squared_error)\n",
    "            \n",
    "num_nan = df_test_scaled.isna().sum().sum()\n",
    "sum_sqr_err = sum(squared_terms)\n",
    "mse = sum_sqr_err/num_nan\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'RMSE FOR PRICE OF WATER IMPUTATION IS {rmse}; SCALE: 2.5 - 100 ish')\n",
    "\n",
    "\n",
    "\n",
    "##################################### n_conflict_total ##############################\n",
    "\n",
    "\n",
    "# defining the columns where we wnat to remone some data\n",
    "features = ['n_conflict_total']\n",
    "\n",
    "#  Inserting NaN values into Experiment Group\n",
    "for col in df_test_scaled[features]:\n",
    "#     20% of the data will be removed (frac = 0.2)\n",
    "# Rows may be selected more that once (replace = true) - only useful if you have more than one column in features\n",
    "    df_test_scaled.loc[df_test_scaled.sample(frac=0.2, replace=True).index, col] = np.nan\n",
    "# df_test_scaled.info()\n",
    "\n",
    "# Creating a list of indices\n",
    "nan_cols = df_test_scaled[features]\n",
    "nan_cols = nan_cols[nan_cols.isna().any(axis = 1)]\n",
    "null_idx = list(nan_cols.index)\n",
    "\n",
    "# Creating Answer key to compare future results against\n",
    "answer_key = df_test.iloc[null_idx]\n",
    "answer_key\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_test_imputed = pd.DataFrame(imputer.fit_transform(df_test_scaled), columns = df_test_scaled.columns)\n",
    "\n",
    "# Invert scaling\n",
    "inverse_df_test_imputed = pd.DataFrame(scaler.inverse_transform(df_test_imputed), columns = df_test_imputed.columns)\n",
    "\n",
    "# Subsetting data to match that of our answer key\n",
    "test = inverse_df_test_imputed.iloc[null_idx]\n",
    "test.head()\n",
    "\n",
    "# Resetting indexes of test and answer_key for iteration\n",
    "test = test.reset_index()\n",
    "test.drop(['index'], axis = 1, inplace= True)\n",
    "answer_key = answer_key.reset_index()\n",
    "answer_key.drop(['index'], axis = 1, inplace= True)\n",
    "\n",
    "# Calculate results\n",
    "results = pd.DataFrame((round((answer_key - test), 3)))\n",
    "# results.head()\n",
    "\n",
    "# calculate RMSE\n",
    "squared_terms = []\n",
    "for col in results[features]:\n",
    "    for i in range(len(results)):\n",
    "        if results[col][i] != 0.00 or results[col][i] != -0.00:\n",
    "            error = results[col][i]\n",
    "            squared_error = error ** 2\n",
    "            squared_terms.append(squared_error)\n",
    "            \n",
    "num_nan = df_test_scaled.isna().sum().sum()\n",
    "sum_sqr_err = sum(squared_terms)\n",
    "mse = sum_sqr_err/num_nan\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'RMSE FOR TOTAL CONFLICT IMPUTATION IS {rmse}; SCALE 1 - 8 ish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ffe21b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       total population  Under-Five Population            GAM            MAM  \\\ncount      5.890000e+02             662.000000     662.000000     517.000000   \nmean       1.679222e+05           34594.969053   12849.631150   10428.901901   \nstd        2.560394e+05           53224.940894   21770.656409   16165.446033   \nmin        1.400000e+04            2800.000000     880.000000     850.349322   \n25%        6.434646e+04           13213.960014    4571.229771    3904.216905   \n50%        9.915700e+04           19852.434528    7145.603532    6083.895167   \n75%        1.803356e+05           36066.500000   14204.392241   12033.672733   \nmax        2.228463e+06          536662.400000  252820.000000  169960.000000   \n\n                SAM  GAM Prevalence  SAM Prevalence  phase3plus_perc_x  \\\ncount    662.000000      662.000000      662.000000         660.000000   \nmean    2255.088426        0.375954        0.064248           0.132167   \nstd     4205.926973        0.096505        0.026155           0.107583   \nmin      106.000000        0.091189        0.010333           0.000000   \n25%      705.448768        0.313069        0.044340           0.060000   \n50%     1223.031450        0.384463        0.063188           0.110000   \n75%     2384.678460        0.443758        0.080600           0.170000   \nmax    48480.000000        0.648001        0.154002           0.580000   \n\n         rainfall  ndvi_score  Price of water  Total alarms  n_conflict_total  \\\ncount  662.000000  655.000000      376.000000    662.000000        587.000000   \nmean    27.807115    0.266650       25.179647      3.434794          4.073363   \nstd     18.523437    0.114215       32.386404      2.382507          7.256452   \nmin      2.981667    0.000000        2.500000      0.000000          1.000000   \n25%     15.399583    0.175833       11.050000      1.500000          1.000000   \n50%     22.693333    0.240000       20.000000      3.000000          2.000000   \n75%     34.692500    0.350000       30.000000      4.833333          3.600000   \nmax    123.440000    0.610000      530.000000     14.000000         68.333333   \n\n       Average of centy  Average of centx  prevalence_6lag  next_prevalence  \\\ncount        662.000000        662.000000       589.000000       589.000000   \nmean           5.560660         45.403898         0.377918         0.370527   \nstd            3.534355          2.502332         0.097524         0.099392   \nmin           -0.853698         41.429420         0.091189         0.091189   \n25%            2.678978         43.432850         0.315706         0.302049   \n50%            4.673877         45.286060         0.384843         0.379600   \n75%            9.229735         47.221660         0.445262         0.440383   \nmax           11.668220         50.794020         0.648001         0.648001   \n\n            month  increase_numeric  district_encoded  \ncount  662.000000        589.000000        662.000000  \nmean     4.335347         -0.007391         38.474320  \nstd      2.983452          0.084438         22.092197  \nmin      1.000000         -0.272960          0.000000  \n25%      1.000000         -0.060938         20.000000  \n50%      7.000000         -0.010172         38.000000  \n75%      7.000000          0.041049         58.000000  \nmax      7.000000          0.344788         76.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total population</th>\n      <th>Under-Five Population</th>\n      <th>GAM</th>\n      <th>MAM</th>\n      <th>SAM</th>\n      <th>GAM Prevalence</th>\n      <th>SAM Prevalence</th>\n      <th>phase3plus_perc_x</th>\n      <th>rainfall</th>\n      <th>ndvi_score</th>\n      <th>Price of water</th>\n      <th>Total alarms</th>\n      <th>n_conflict_total</th>\n      <th>Average of centy</th>\n      <th>Average of centx</th>\n      <th>prevalence_6lag</th>\n      <th>next_prevalence</th>\n      <th>month</th>\n      <th>increase_numeric</th>\n      <th>district_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.890000e+02</td>\n      <td>662.000000</td>\n      <td>662.000000</td>\n      <td>517.000000</td>\n      <td>662.000000</td>\n      <td>662.000000</td>\n      <td>662.000000</td>\n      <td>660.000000</td>\n      <td>662.000000</td>\n      <td>655.000000</td>\n      <td>376.000000</td>\n      <td>662.000000</td>\n      <td>587.000000</td>\n      <td>662.000000</td>\n      <td>662.000000</td>\n      <td>589.000000</td>\n      <td>589.000000</td>\n      <td>662.000000</td>\n      <td>589.000000</td>\n      <td>662.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.679222e+05</td>\n      <td>34594.969053</td>\n      <td>12849.631150</td>\n      <td>10428.901901</td>\n      <td>2255.088426</td>\n      <td>0.375954</td>\n      <td>0.064248</td>\n      <td>0.132167</td>\n      <td>27.807115</td>\n      <td>0.266650</td>\n      <td>25.179647</td>\n      <td>3.434794</td>\n      <td>4.073363</td>\n      <td>5.560660</td>\n      <td>45.403898</td>\n      <td>0.377918</td>\n      <td>0.370527</td>\n      <td>4.335347</td>\n      <td>-0.007391</td>\n      <td>38.474320</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.560394e+05</td>\n      <td>53224.940894</td>\n      <td>21770.656409</td>\n      <td>16165.446033</td>\n      <td>4205.926973</td>\n      <td>0.096505</td>\n      <td>0.026155</td>\n      <td>0.107583</td>\n      <td>18.523437</td>\n      <td>0.114215</td>\n      <td>32.386404</td>\n      <td>2.382507</td>\n      <td>7.256452</td>\n      <td>3.534355</td>\n      <td>2.502332</td>\n      <td>0.097524</td>\n      <td>0.099392</td>\n      <td>2.983452</td>\n      <td>0.084438</td>\n      <td>22.092197</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.400000e+04</td>\n      <td>2800.000000</td>\n      <td>880.000000</td>\n      <td>850.349322</td>\n      <td>106.000000</td>\n      <td>0.091189</td>\n      <td>0.010333</td>\n      <td>0.000000</td>\n      <td>2.981667</td>\n      <td>0.000000</td>\n      <td>2.500000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>-0.853698</td>\n      <td>41.429420</td>\n      <td>0.091189</td>\n      <td>0.091189</td>\n      <td>1.000000</td>\n      <td>-0.272960</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6.434646e+04</td>\n      <td>13213.960014</td>\n      <td>4571.229771</td>\n      <td>3904.216905</td>\n      <td>705.448768</td>\n      <td>0.313069</td>\n      <td>0.044340</td>\n      <td>0.060000</td>\n      <td>15.399583</td>\n      <td>0.175833</td>\n      <td>11.050000</td>\n      <td>1.500000</td>\n      <td>1.000000</td>\n      <td>2.678978</td>\n      <td>43.432850</td>\n      <td>0.315706</td>\n      <td>0.302049</td>\n      <td>1.000000</td>\n      <td>-0.060938</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>9.915700e+04</td>\n      <td>19852.434528</td>\n      <td>7145.603532</td>\n      <td>6083.895167</td>\n      <td>1223.031450</td>\n      <td>0.384463</td>\n      <td>0.063188</td>\n      <td>0.110000</td>\n      <td>22.693333</td>\n      <td>0.240000</td>\n      <td>20.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>4.673877</td>\n      <td>45.286060</td>\n      <td>0.384843</td>\n      <td>0.379600</td>\n      <td>7.000000</td>\n      <td>-0.010172</td>\n      <td>38.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.803356e+05</td>\n      <td>36066.500000</td>\n      <td>14204.392241</td>\n      <td>12033.672733</td>\n      <td>2384.678460</td>\n      <td>0.443758</td>\n      <td>0.080600</td>\n      <td>0.170000</td>\n      <td>34.692500</td>\n      <td>0.350000</td>\n      <td>30.000000</td>\n      <td>4.833333</td>\n      <td>3.600000</td>\n      <td>9.229735</td>\n      <td>47.221660</td>\n      <td>0.445262</td>\n      <td>0.440383</td>\n      <td>7.000000</td>\n      <td>0.041049</td>\n      <td>58.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.228463e+06</td>\n      <td>536662.400000</td>\n      <td>252820.000000</td>\n      <td>169960.000000</td>\n      <td>48480.000000</td>\n      <td>0.648001</td>\n      <td>0.154002</td>\n      <td>0.580000</td>\n      <td>123.440000</td>\n      <td>0.610000</td>\n      <td>530.000000</td>\n      <td>14.000000</td>\n      <td>68.333333</td>\n      <td>11.668220</td>\n      <td>50.794020</td>\n      <td>0.648001</td>\n      <td>0.648001</td>\n      <td>7.000000</td>\n      <td>0.344788</td>\n      <td>76.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80c060e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we do the actual imputation for the columns\n",
    "\n",
    "# defining the columns where we wnat to remone some data\n",
    "\n",
    "df_imputation = df.copy()\n",
    "df_imputation = df_imputation.drop(['date', 'district', 'Average of centy', 'Average of centx'], axis = 1)\n",
    "\n",
    "#  we need to normalize the data to make sure the imputer isn't bisaed\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_imputation), columns = df_imputation.columns)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_scaled_imputed = pd.DataFrame(imputer.fit_transform(df_scaled), columns = df_scaled.columns)\n",
    "df_imputed = pd.DataFrame(scaler.inverse_transform(df_scaled_imputed), columns = df_scaled_imputed.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bc2b191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "date                       0\ndistrict                   0\ntotal population          73\nUnder-Five Population      0\nGAM                        0\nMAM                      145\nSAM                        0\nGAM Prevalence             0\nSAM Prevalence             0\nphase3plus_perc_x          2\nrainfall                   0\nndvi_score                 7\nPrice of water           286\nTotal alarms               0\nn_conflict_total          75\nAverage of centy           0\nAverage of centx           0\nprevalence_6lag           73\nnext_prevalence           73\nmonth                      0\nincrease                  73\nincrease_numeric          73\ndistrict_encoded           0\ndtype: int64"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) - df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90905000",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ndvi_score', 'phase3plus_perc_x']] = df_imputed[['ndvi_score', 'phase3plus_perc_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d80df84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "date                       0\ndistrict                   0\ntotal population          73\nUnder-Five Population      0\nGAM                        0\nMAM                      145\nSAM                        0\nGAM Prevalence             0\nSAM Prevalence             0\nphase3plus_perc_x          0\nrainfall                   0\nndvi_score                 0\nPrice of water           286\nTotal alarms               0\nn_conflict_total          75\nAverage of centy           0\nAverage of centx           0\nprevalence_6lag           73\nnext_prevalence           73\nmonth                      0\nincrease                  73\nincrease_numeric          73\ndistrict_encoded           0\ndtype: int64"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) - df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "547eb3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"knnImputed_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
