{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook will standardize all district names according to the 'Somalia Districts' word document in the drive of the following files: Admissions, FSNAU_riskfactors, ipc, ipc2, locations, prevalance_estimates. <br>\n",
    "Make sure to have this file in the same folder as your data and have the data in the separate 'data' folder if you want to use the same path for the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define variables and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "districts = ['Adan Yabaal', 'Afgooye', 'Afmadow', 'Baardheere', 'Badhaadhe', 'Baidoa', \n",
    " 'Baydhaba/Bardaale', 'Baki', 'Balcad', 'Banadir', 'Bandarbeyla', 'Baraawe', 'Belet Weyne', 'Belet Weyne (Mataban)','Belet Xaawo', \n",
    "'Berbera', 'Borama', 'Bossaso', 'Bu\\'aale', 'Bulo Burto', 'Burco', 'Burtinle', 'Buuhoodle',\n",
    "'Buur Hakaba', 'Cabudwaaq', 'Cadaado', 'Cadale', 'Caluula', 'Caynabo', 'Ceel Afweyn', 'Ceel Barde',\n",
    "'Ceel Buur', 'Ceel Dheer', 'Ceel Waaq', 'Ceerigaabo', 'Dhuusamarreeb', 'Diinsoor', 'Doolow',\n",
    "'Eyl', 'Gaalkacyo', 'Galdogob', 'Garbahaarey', 'Garoowe', 'Gebiley', 'Hargeysa', 'Hobyo', 'Iskushuban',\n",
    "'Jalalaqsi', 'Jamaame', 'Jariiban', 'Jilib', 'Jowhar', 'Kismaayo', 'Kurtunwaarey', 'Laas Caanood', 'Laasqoray', \n",
    "'Laasqoray/Badhan', 'Badhan', 'Lughaye', 'Luuq', 'Marka', 'Owdweyne', 'Qandala', 'Qansax Dheere', 'Qardho', 'Qoryooley', \n",
    "'Rab Dhuure', 'Saakow', 'Sablaale', 'Sheikh', 'Taleex', 'Tayeeglow', 'Waajid', 'Wanla Weyn',\n",
    "'Xarardheere', 'Xudun', 'Xudur', 'Zeylac']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def levenshteinDistanceDP(token1, token2):\n",
    "    '''\n",
    "    This function implements the levenshtein text similarity measure \n",
    "    and returns a numeric value representing the distance between two words\n",
    "    '''\n",
    "    distances = numpy.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def update_districts(df):\n",
    "    '''\n",
    "    This function checks whether the district name is the standard. \n",
    "    If it is not, then the word is corrected by known value or by levenshtein distance.\n",
    "    It creates a list with all the standard districts and sets that list as district column.\n",
    "    Uncomment print statements in last loop to see what districts changed by levenshtein algo.\n",
    "    '''\n",
    "\n",
    "    new_series = []\n",
    "    for token1 in df['district']:\n",
    "\n",
    "        #If district is standard append to list\n",
    "        if token1 in districts: \n",
    "            new_series.append(token1)\n",
    "\n",
    "        #If district is not standard and a known variant\n",
    "        elif token1 == 'Mogadishu': \n",
    "            correct_district = 'Banadir'\n",
    "            new_series.append(correct_district)\n",
    "        elif token1 == 'Baydhaba': \n",
    "            correct_district = 'Baidoa'\n",
    "            new_series.append(correct_district)\n",
    "        elif token1 == 'Belethawa': \n",
    "            correct_district = 'Belet Xaawo'\n",
    "            new_series.append(correct_district)\n",
    "        elif token1 == 'Abudwak': \n",
    "            correct_district = 'Cabudwaaq'\n",
    "            new_series.append(correct_district)\n",
    "        elif token1 == 'Adado': \n",
    "            correct_district = 'Cadaado'\n",
    "            new_series.append(correct_district)\n",
    "\n",
    "        #If district is not a known variant, apply levenshtein algo\n",
    "        elif token1 not in districts: \n",
    "            #print('old: %s' % token1)\n",
    "            distances = []\n",
    "            for token2 in districts: \n",
    "                distances.append(levenshteinDistanceDP(token1, token2))\n",
    "            min_value = min(distances)\n",
    "            correct_district = districts[distances.index(min_value)]\n",
    "            #print('new: %s' % correct_district)\n",
    "            new_series.append(correct_district)\n",
    "    df['district'] = new_series\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Read files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Change path to your data path if needed \n",
    "\n",
    "path_admissions = 'data/admissions.csv'\n",
    "path_FSNAU = 'data/FSNAU_riskfactors.csv'\n",
    "path_ipc = 'data/ipc.csv'\n",
    "path_ipc2 = 'data/ipc2.csv'\n",
    "path_locations = 'data/locations.csv'\n",
    "path_prevalence = 'data/prevalence_estimates.csv'\n",
    "path_production = 'data/production.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_admissions = pandas.read_csv(path_admissions)\n",
    "\n",
    "df_FSNAU = pandas.read_csv(path_FSNAU)\n",
    "\n",
    "df_ipc = pandas.read_csv(path_ipc)\n",
    "df_ipc.rename({'area': 'district'}, axis=1, inplace=True)\n",
    "\n",
    "df_ipc2 = pandas.read_csv(path_ipc2)\n",
    "\n",
    "df_locations = pandas.read_csv(path_locations)\n",
    "df_locations = df_locations[df_locations.district != 'Grand Total']\n",
    "\n",
    "df_prevalence = pandas.read_csv(path_prevalence)\n",
    "\n",
    "df_production = pandas.read_csv(path_production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Update District Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_admissions = update_districts(df_admissions)\n",
    "df_FSNAU = update_districts(df_FSNAU)\n",
    "df_ipc = update_districts(df_ipc)\n",
    "df_ipc2 = update_districts(df_ipc2)\n",
    "df_locations = update_districts(df_locations)\n",
    "df_prevalence = update_districts(df_prevalence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Write new dataframes to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_admissions.to_csv(path_admissions)\n",
    "df_FSNAU.to_csv(path_FSNAU)\n",
    "df_ipc.to_csv(path_ipc)\n",
    "df_ipc2.to_csv(path_ipc2)\n",
    "df_locations.to_csv(path_locations)\n",
    "df_prevalence.to_csv(path_prevalence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}