{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from helper_metrics import count_missing_district, count_missing_district_total\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics         import mean_absolute_error, accuracy_score\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/mixImputed_data.csv\").iloc[:,1:]\n",
    "knn_df = pd.read_csv(\"data/knnImputed_data.csv\").iloc[:,1:]\n",
    "df[[\"phase3plus_perc_x\", \"ndvi_score\"]] = knn_df[[\"phase3plus_perc_x\", \"ndvi_score\"]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "increase_numeric    73\nincrease            73\nnext_prevalence     73\nprevalence_6lag     73\ndate                 0\ndtype: int64"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity checks\n",
    "df.isna().sum().sort_values(ascending=False)[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "73"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.district.unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create train and test sets\n",
    "We must drop nan values in X for the RF model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "y = df.next_prevalence.dropna()\n",
    "X = df.select_dtypes(exclude=[\"object\", \"category\"]).drop(\"next_prevalence\", axis=1).dropna(axis=1).iloc[:len(y)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Subsets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Function that returns every possible subset (except the empty set) of the input list l\n",
    "def subsets(l: object) -> object:\n",
    "    subset_list = []\n",
    "    for i in range(len(l) + 1):\n",
    "        for j in range(i):\n",
    "            subset_list.append(l[j: i])\n",
    "    return subset_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross Validation Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "365"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "73*5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [3:02:30<00:00, 171.11s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Define search space for number of trees in random forest and depth of trees\n",
    "num_trees_min = 64\n",
    "num_trees_max = 128\n",
    "\n",
    "depth_min = 2\n",
    "depth_max = 7\n",
    "\n",
    "parameter_scores = []\n",
    "\n",
    "for num_trees in tqdm(range(num_trees_min, num_trees_max)):\n",
    "\n",
    "    for depth in range(depth_min, depth_max):\n",
    "\n",
    "        # Investigate every subset of explanatory variables\n",
    "        for features in subsets(X.columns):\n",
    "            # First CV split. The 219 refers to the first 3 observations for the 73 districts in the data.\n",
    "            Xtrain = X[:219][features].copy().values\n",
    "            ytrain = y[:219]\n",
    "            Xtest = X[219:292][features].copy().values\n",
    "            ytest = y[219:292]\n",
    "\n",
    "            # Create a RandomForestRegressor with the selected hyperparameters and random state 0.\n",
    "            clf = RandomForestRegressor(n_estimators=num_trees, max_depth=depth, random_state=0, n_jobs=-1)\n",
    "\n",
    "            # Fit to the training data\n",
    "            clf.fit(Xtrain, ytrain)\n",
    "\n",
    "            # Make a prediction on the test data\n",
    "            predictions = clf.predict(Xtest)\n",
    "\n",
    "            # Calculate mean absolute error\n",
    "            MAE1 = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "            # Second CV split. The 292 refers to the first 4 observations for the 73 districts in the data.\n",
    "            Xtrain = X[:292][features].copy().values\n",
    "            ytrain = y[:292]\n",
    "            Xtest = X[292:365][features].copy().values\n",
    "            ytest = y[292:365]\n",
    "\n",
    "            # Create a RandomForestRegressor with the selected hyperparameters and random state 0.\n",
    "            clf = RandomForestRegressor(n_estimators=num_trees, max_depth=depth, random_state=0, n_jobs=-1)\n",
    "\n",
    "            # Fit to the training data\n",
    "            clf.fit(Xtrain, ytrain)\n",
    "\n",
    "            # Make a prediction on the test data\n",
    "            predictions = clf.predict(Xtest)\n",
    "\n",
    "            # Calculate mean absolute error\n",
    "            MAE2 = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "            # Calculate the mean MAE over the two folds\n",
    "            mean_MAE = (MAE1 + MAE2) / 2\n",
    "\n",
    "            # Store the mean MAE together with the used hyperparameters in list\n",
    "            parameter_scores.append((mean_MAE, num_trees, depth, features))\n",
    "\n",
    "# Sort the models based on score and retrieve the hyperparameters of the best model\n",
    "parameter_scores.sort(key=lambda x: x[0])\n",
    "best_model_score = parameter_scores[0][0]\n",
    "best_model_trees = parameter_scores[0][1]\n",
    "best_model_depth = parameter_scores[0][2]\n",
    "best_model_columns = list(parameter_scores[0][3])\n",
    "\n",
    "'''------------SECTION FINAL EVALUATION--------------'''\n",
    "y = df['next_prevalence'].values\n",
    "X = df[best_model_columns].values\n",
    "\n",
    "# If there is only one explanatory variable, the values need to be reshaped for the model\n",
    "if len(best_model_columns) == 1:\n",
    "    X = X.reshape(-1, 1)\n",
    "\n",
    "# Peform evaluation on full data\n",
    "Xtrain = X[:365]\n",
    "ytrain = y[:365]\n",
    "Xtest = X[365:]\n",
    "ytest = y[365:]\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=best_model_trees, max_depth=best_model_depth, random_state=0, n_jobs=-1)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "predictions = clf.predict(Xtest)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "(88209, 88209)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate MAE\n",
    "y_true = pd.Series(ytest[:-73]).drop(69)\n",
    "y_pred = pd.Series(predictions[:-73]).drop(69)\n",
    "\n",
    "#MAE = mean_absolute_error(ytest, predictions)\n",
    "MAE = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Generate boolean values for increase or decrease in prevalence. 0 if next prevalence is smaller than current prevalence, 1 otherwise.\n",
    "increase = [0 if x < y else 1 for x in df.iloc[365:]['next_prevalence'] for y in df.iloc[365:]['GAM Prevalence']]\n",
    "predicted_increase = [0 if x < y else 1 for x in predictions for y in df.iloc[365:]['GAM Prevalence']]\n",
    "\n",
    "len(increase), len(predicted_increase)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of trees: 85\n",
      "max_depth: 6\n",
      "columns: ['ndvi_score', 'Price of water', 'Total alarms', 'n_conflict_total', 'Average of centy', 'Average of centx']\n",
      "MAE: 0.06, Accuracy: 76.2%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy of predicted boolean increase/decrease\n",
    "acc = accuracy_score(increase, predicted_increase)\n",
    "\n",
    "# Print model parameters\n",
    "print('no. of trees: ' + str(best_model_trees) + '\\nmax_depth: ' + str(best_model_depth) + '\\ncolumns: ' + str(\n",
    "    best_model_columns))\n",
    "\n",
    "# Print model scores\n",
    "print(f\"MAE: {np.round(MAE,4)}, Accuracy: {np.round(acc,3)*100}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
