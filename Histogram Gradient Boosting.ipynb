{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "from helper_metrics import count_missing_district, count_missing_district_total, make_confusion_matrix, calculate_results\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.experimental    import enable_iterative_imputer\n",
    "from sklearn.impute          import IterativeImputer\n",
    "from sklearn.experimental    import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble        import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics         import mean_absolute_error, accuracy_score\n",
    "from tqdm import tqdm\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "           date     district  total population  Under-Five Population  \\\n0    2017-07-01  Adan Yabaal       65262.96000            13052.59200   \n1    2017-07-01         Luuq      100476.76500            20095.35300   \n2    2017-07-01  Buur Hakaba      165968.46000            33193.69200   \n3    2017-07-01        Marka      282222.76500            56444.55300   \n4    2017-07-01    Buuhoodle       71317.71000            14263.54200   \n..          ...          ...               ...                    ...   \n651  2021-07-01  Belet Xaawo               NaN            29314.59999   \n652  2021-07-01        Jilib               NaN            28586.09073   \n653  2021-07-01      Caynabo               NaN            16276.00000   \n654  2021-07-01   Rab Dhuure               NaN            15127.60000   \n655  2021-07-01      Baraawe               NaN            10954.96873   \n\n            GAM         MAM        SAM  GAM Prevalence  SAM Prevalence  \\\n0    4819.01697  3733.04131 1085.97565         0.36920         0.08320   \n1    8673.15435  7366.95641 1306.19795         0.43160         0.06500   \n2   11909.89669  8198.84192 3711.05477         0.35880         0.11180   \n3   20839.32897 16143.14216 4696.18681         0.36920         0.08320   \n4    4858.16241  3652.89311 1205.26930         0.34060         0.08450   \n..          ...         ...        ...             ...             ...   \n651  9820.00000         NaN 1310.00000         0.33499         0.04469   \n652 11560.00000         NaN 2770.00000         0.40439         0.09690   \n653  3540.00000         NaN  270.00000         0.21750         0.01659   \n654  6940.00000         NaN 1560.00000         0.45876         0.10312   \n655  5100.00000         NaN 1060.00000         0.46554         0.09676   \n\n     phase3plus_perc_x  ...  Total alarms  n_conflict_total  Average of centy  \\\n0              0.18000  ...       2.16667               NaN           3.54944   \n1              0.21000  ...       7.83333           1.50000           3.79293   \n2              0.35000  ...       6.16667           4.66667           2.48537   \n3              0.17000  ...      11.83333          11.83333           1.74015   \n4              0.37000  ...       2.33333           2.50000           8.46016   \n..                 ...  ...           ...               ...               ...   \n651            0.15000  ...       3.50000           1.20000           3.43559   \n652            0.11000  ...       6.16667           2.00000           0.64501   \n653            0.17000  ...       0.50000           1.00000           9.28238   \n654            0.07000  ...       0.16667           1.00000           4.24328   \n655            0.06000  ...       2.50000           6.00000           1.10831   \n\n     Average of centx  prevalence_6lag  next_prevalence  month  increase  \\\n0            46.54467              NaN          0.35100      7     False   \n1            42.69760              NaN          0.39260      7     False   \n2            44.00688              NaN          0.28860      7     False   \n3            44.71787              NaN          0.35100      7     False   \n4            46.66129              NaN          0.20280      7     False   \n..                ...              ...              ...    ...       ...   \n651          41.73370          0.38353              NaN      7       NaN   \n652          43.05589          0.31242              NaN      7       NaN   \n653          46.49009          0.25746              NaN      7       NaN   \n654          43.21162          0.50720              NaN      7       NaN   \n655          43.84067          0.49119              NaN      7       NaN   \n\n     increase_numeric  district_encoded  \n0            -0.01820                 0  \n1            -0.03900                59  \n2            -0.07020                24  \n3            -0.01820                60  \n4            -0.13780                23  \n..                ...               ...  \n651               NaN                15  \n652               NaN                51  \n653               NaN                29  \n654               NaN                66  \n655               NaN                11  \n\n[656 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>district</th>\n      <th>total population</th>\n      <th>Under-Five Population</th>\n      <th>GAM</th>\n      <th>MAM</th>\n      <th>SAM</th>\n      <th>GAM Prevalence</th>\n      <th>SAM Prevalence</th>\n      <th>phase3plus_perc_x</th>\n      <th>...</th>\n      <th>Total alarms</th>\n      <th>n_conflict_total</th>\n      <th>Average of centy</th>\n      <th>Average of centx</th>\n      <th>prevalence_6lag</th>\n      <th>next_prevalence</th>\n      <th>month</th>\n      <th>increase</th>\n      <th>increase_numeric</th>\n      <th>district_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-07-01</td>\n      <td>Adan Yabaal</td>\n      <td>65262.96000</td>\n      <td>13052.59200</td>\n      <td>4819.01697</td>\n      <td>3733.04131</td>\n      <td>1085.97565</td>\n      <td>0.36920</td>\n      <td>0.08320</td>\n      <td>0.18000</td>\n      <td>...</td>\n      <td>2.16667</td>\n      <td>NaN</td>\n      <td>3.54944</td>\n      <td>46.54467</td>\n      <td>NaN</td>\n      <td>0.35100</td>\n      <td>7</td>\n      <td>False</td>\n      <td>-0.01820</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-07-01</td>\n      <td>Luuq</td>\n      <td>100476.76500</td>\n      <td>20095.35300</td>\n      <td>8673.15435</td>\n      <td>7366.95641</td>\n      <td>1306.19795</td>\n      <td>0.43160</td>\n      <td>0.06500</td>\n      <td>0.21000</td>\n      <td>...</td>\n      <td>7.83333</td>\n      <td>1.50000</td>\n      <td>3.79293</td>\n      <td>42.69760</td>\n      <td>NaN</td>\n      <td>0.39260</td>\n      <td>7</td>\n      <td>False</td>\n      <td>-0.03900</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017-07-01</td>\n      <td>Buur Hakaba</td>\n      <td>165968.46000</td>\n      <td>33193.69200</td>\n      <td>11909.89669</td>\n      <td>8198.84192</td>\n      <td>3711.05477</td>\n      <td>0.35880</td>\n      <td>0.11180</td>\n      <td>0.35000</td>\n      <td>...</td>\n      <td>6.16667</td>\n      <td>4.66667</td>\n      <td>2.48537</td>\n      <td>44.00688</td>\n      <td>NaN</td>\n      <td>0.28860</td>\n      <td>7</td>\n      <td>False</td>\n      <td>-0.07020</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-07-01</td>\n      <td>Marka</td>\n      <td>282222.76500</td>\n      <td>56444.55300</td>\n      <td>20839.32897</td>\n      <td>16143.14216</td>\n      <td>4696.18681</td>\n      <td>0.36920</td>\n      <td>0.08320</td>\n      <td>0.17000</td>\n      <td>...</td>\n      <td>11.83333</td>\n      <td>11.83333</td>\n      <td>1.74015</td>\n      <td>44.71787</td>\n      <td>NaN</td>\n      <td>0.35100</td>\n      <td>7</td>\n      <td>False</td>\n      <td>-0.01820</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-07-01</td>\n      <td>Buuhoodle</td>\n      <td>71317.71000</td>\n      <td>14263.54200</td>\n      <td>4858.16241</td>\n      <td>3652.89311</td>\n      <td>1205.26930</td>\n      <td>0.34060</td>\n      <td>0.08450</td>\n      <td>0.37000</td>\n      <td>...</td>\n      <td>2.33333</td>\n      <td>2.50000</td>\n      <td>8.46016</td>\n      <td>46.66129</td>\n      <td>NaN</td>\n      <td>0.20280</td>\n      <td>7</td>\n      <td>False</td>\n      <td>-0.13780</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>651</th>\n      <td>2021-07-01</td>\n      <td>Belet Xaawo</td>\n      <td>NaN</td>\n      <td>29314.59999</td>\n      <td>9820.00000</td>\n      <td>NaN</td>\n      <td>1310.00000</td>\n      <td>0.33499</td>\n      <td>0.04469</td>\n      <td>0.15000</td>\n      <td>...</td>\n      <td>3.50000</td>\n      <td>1.20000</td>\n      <td>3.43559</td>\n      <td>41.73370</td>\n      <td>0.38353</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>652</th>\n      <td>2021-07-01</td>\n      <td>Jilib</td>\n      <td>NaN</td>\n      <td>28586.09073</td>\n      <td>11560.00000</td>\n      <td>NaN</td>\n      <td>2770.00000</td>\n      <td>0.40439</td>\n      <td>0.09690</td>\n      <td>0.11000</td>\n      <td>...</td>\n      <td>6.16667</td>\n      <td>2.00000</td>\n      <td>0.64501</td>\n      <td>43.05589</td>\n      <td>0.31242</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>653</th>\n      <td>2021-07-01</td>\n      <td>Caynabo</td>\n      <td>NaN</td>\n      <td>16276.00000</td>\n      <td>3540.00000</td>\n      <td>NaN</td>\n      <td>270.00000</td>\n      <td>0.21750</td>\n      <td>0.01659</td>\n      <td>0.17000</td>\n      <td>...</td>\n      <td>0.50000</td>\n      <td>1.00000</td>\n      <td>9.28238</td>\n      <td>46.49009</td>\n      <td>0.25746</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>654</th>\n      <td>2021-07-01</td>\n      <td>Rab Dhuure</td>\n      <td>NaN</td>\n      <td>15127.60000</td>\n      <td>6940.00000</td>\n      <td>NaN</td>\n      <td>1560.00000</td>\n      <td>0.45876</td>\n      <td>0.10312</td>\n      <td>0.07000</td>\n      <td>...</td>\n      <td>0.16667</td>\n      <td>1.00000</td>\n      <td>4.24328</td>\n      <td>43.21162</td>\n      <td>0.50720</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>655</th>\n      <td>2021-07-01</td>\n      <td>Baraawe</td>\n      <td>NaN</td>\n      <td>10954.96873</td>\n      <td>5100.00000</td>\n      <td>NaN</td>\n      <td>1060.00000</td>\n      <td>0.46554</td>\n      <td>0.09676</td>\n      <td>0.06000</td>\n      <td>...</td>\n      <td>2.50000</td>\n      <td>6.00000</td>\n      <td>1.10831</td>\n      <td>43.84067</td>\n      <td>0.49119</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n<p>656 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/semiyearly_chosen_columns.csv\").iloc[:,1:]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create train and test sets\n",
    "X does not need to drop nan values as HGBR can handle nan inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "y = df.next_prevalence.dropna()\n",
    "X = df.select_dtypes(exclude=[\"object\", \"category\"]).iloc[:len(y)].drop(\"next_prevalence\", axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Subsets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Function that returns every possible subset (except the empty set) of the input list l\n",
    "def subsets(l: object) -> object:\n",
    "    subset_list = []\n",
    "    for i in range(len(l) + 1):\n",
    "        for j in range(i):\n",
    "            subset_list.append(l[j: i])\n",
    "    return subset_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross Validation Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "365"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "73*5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [1:20:59<00:00, 147.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.000 GB of training data: 0.003 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/100] 1 tree, 12 leaves, max depth = 6, in 0.003s\n",
      "[2/100] 1 tree, 13 leaves, max depth = 6, in 0.003s\n",
      "[3/100] 1 tree, 14 leaves, max depth = 5, in 0.003s\n",
      "[4/100] 1 tree, 13 leaves, max depth = 6, in 0.003s\n",
      "[5/100] 1 tree, 13 leaves, max depth = 5, in 0.003s\n",
      "[6/100] 1 tree, 14 leaves, max depth = 6, in 0.003s\n",
      "[7/100] 1 tree, 15 leaves, max depth = 6, in 0.003s\n",
      "[8/100] 1 tree, 14 leaves, max depth = 6, in 0.003s\n",
      "[9/100] 1 tree, 14 leaves, max depth = 5, in 0.003s\n",
      "[10/100] 1 tree, 15 leaves, max depth = 6, in 0.003s\n",
      "[11/100] 1 tree, 12 leaves, max depth = 6, in 0.003s\n",
      "[12/100] 1 tree, 15 leaves, max depth = 6, in 0.003s\n",
      "[13/100] 1 tree, 10 leaves, max depth = 6, in 0.003s\n",
      "[14/100] 1 tree, 14 leaves, max depth = 6, in 0.003s\n",
      "[15/100] 1 tree, 9 leaves, max depth = 6, in 0.003s\n",
      "[16/100] 1 tree, 12 leaves, max depth = 6, in 0.003s\n",
      "[17/100] 1 tree, 15 leaves, max depth = 6, in 0.003s\n",
      "[18/100] 1 tree, 9 leaves, max depth = 6, in 0.003s\n",
      "[19/100] 1 tree, 8 leaves, max depth = 6, in 0.003s\n",
      "[20/100] 1 tree, 15 leaves, max depth = 6, in 0.003s\n",
      "[21/100] 1 tree, 10 leaves, max depth = 6, in 0.002s\n",
      "[22/100] 1 tree, 8 leaves, max depth = 6, in 0.003s\n",
      "[23/100] 1 tree, 15 leaves, max depth = 6, in 0.003s\n",
      "[24/100] 1 tree, 8 leaves, max depth = 6, in 0.003s\n",
      "[25/100] 1 tree, 9 leaves, max depth = 6, in 0.002s\n",
      "[26/100] 1 tree, 15 leaves, max depth = 6, in 0.004s\n",
      "[27/100] 1 tree, 9 leaves, max depth = 6, in 0.003s\n",
      "[28/100] 1 tree, 15 leaves, max depth = 6, in 0.003s\n",
      "[29/100] 1 tree, 8 leaves, max depth = 6, in 0.002s\n",
      "[30/100] 1 tree, 8 leaves, max depth = 6, in 0.002s\n",
      "[31/100] 1 tree, 15 leaves, max depth = 6, in 0.003s\n",
      "[32/100] 1 tree, 9 leaves, max depth = 6, in 0.003s\n",
      "[33/100] 1 tree, 9 leaves, max depth = 6, in 0.003s\n",
      "[34/100] 1 tree, 15 leaves, max depth = 6, in 0.004s\n",
      "[35/100] 1 tree, 9 leaves, max depth = 6, in 0.002s\n",
      "[36/100] 1 tree, 11 leaves, max depth = 6, in 0.003s\n",
      "[37/100] 1 tree, 12 leaves, max depth = 6, in 0.003s\n",
      "[38/100] 1 tree, 9 leaves, max depth = 6, in 0.002s\n",
      "[39/100] 1 tree, 8 leaves, max depth = 6, in 0.002s\n",
      "[40/100] 1 tree, 11 leaves, max depth = 6, in 0.003s\n",
      "[41/100] 1 tree, 12 leaves, max depth = 6, in 0.003s\n",
      "[42/100] 1 tree, 12 leaves, max depth = 6, in 0.003s\n",
      "[43/100] 1 tree, 9 leaves, max depth = 6, in 0.003s\n",
      "[44/100] 1 tree, 10 leaves, max depth = 6, in 0.003s\n",
      "[45/100] 1 tree, 9 leaves, max depth = 6, in 0.003s\n",
      "[46/100] 1 tree, 11 leaves, max depth = 6, in 0.003s\n",
      "[47/100] 1 tree, 10 leaves, max depth = 6, in 0.002s\n",
      "[48/100] 1 tree, 14 leaves, max depth = 6, in 0.003s\n",
      "[49/100] 1 tree, 9 leaves, max depth = 6, in 0.003s\n",
      "[50/100] 1 tree, 11 leaves, max depth = 6, in 0.003s\n",
      "[51/100] 1 tree, 11 leaves, max depth = 6, in 0.003s\n",
      "[52/100] 1 tree, 11 leaves, max depth = 6, in 0.003s\n",
      "[53/100] 1 tree, 14 leaves, max depth = 6, in 0.003s\n",
      "[54/100] 1 tree, 11 leaves, max depth = 6, in 0.003s\n",
      "[55/100] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tree, 8 leaves, max depth = 6, in 0.003s\n",
      "[56/100] 1 tree, 11 leaves, max depth = 6, in 0.003s\n",
      "[57/100] 1 tree, 10 leaves, max depth = 6, in 0.003s\n",
      "[58/100] 1 tree, 10 leaves, max depth = 6, in 0.003s\n",
      "[59/100] 1 tree, 9 leaves, max depth = 6, in 0.003s\n",
      "[60/100] 1 tree, 9 leaves, max depth = 6, in 0.002s\n",
      "[61/100] 1 tree, 12 leaves, max depth = 6, in 0.003s\n",
      "[62/100] 1 tree, 13 leaves, max depth = 6, in 0.003s\n",
      "[63/100] 1 tree, 11 leaves, max depth = 6, in 0.003s\n",
      "[64/100] 1 tree, 9 leaves, max depth = 6, in 0.002s\n",
      "[65/100] 1 tree, 11 leaves, max depth = 6, in 0.003s\n",
      "[66/100] 1 tree, 10 leaves, max depth = 6, in 0.002s\n",
      "[67/100] 1 tree, 8 leaves, max depth = 6, in 0.002s\n",
      "[68/100] 1 tree, 10 leaves, max depth = 6, in 0.002s\n",
      "[69/100] 1 tree, 11 leaves, max depth = 6, in 0.002s\n",
      "[70/100] 1 tree, 10 leaves, max depth = 6, in 0.002s\n",
      "[71/100] 1 tree, 11 leaves, max depth = 6, in 0.002s\n",
      "[72/100] 1 tree, 10 leaves, max depth = 6, in 0.003s\n",
      "[73/100] 1 tree, 7 leaves, max depth = 6, in 0.002s\n",
      "[74/100] 1 tree, 13 leaves, max depth = 6, in 0.003s\n",
      "[75/100] 1 tree, 14 leaves, max depth = 6, in 0.003s\n",
      "[76/100] 1 tree, 10 leaves, max depth = 6, in 0.003s\n",
      "[77/100] 1 tree, 11 leaves, max depth = 6, in 0.003s\n",
      "[78/100] 1 tree, 10 leaves, max depth = 6, in 0.003s\n",
      "[79/100] 1 tree, 11 leaves, max depth = 6, in 0.003s\n",
      "[80/100] 1 tree, 9 leaves, max depth = 6, in 0.003s\n",
      "[81/100] 1 tree, 12 leaves, max depth = 6, in 0.005s\n",
      "[82/100] 1 tree, 11 leaves, max depth = 6, in 0.004s\n",
      "[83/100] 1 tree, 9 leaves, max depth = 6, in 0.004s\n",
      "[84/100] 1 tree, 15 leaves, max depth = 6, in 0.004s\n",
      "[85/100] 1 tree, 10 leaves, max depth = 6, in 0.003s\n",
      "[86/100] 1 tree, 13 leaves, max depth = 6, in 0.005s\n",
      "[87/100] 1 tree, 13 leaves, max depth = 6, in 0.004s\n",
      "[88/100] 1 tree, 10 leaves, max depth = 6, in 0.003s\n",
      "[89/100] 1 tree, 11 leaves, max depth = 6, in 0.003s\n",
      "[90/100] 1 tree, 8 leaves, max depth = 6, in 0.003s\n",
      "[91/100] 1 tree, 8 leaves, max depth = 6, in 0.003s\n",
      "[92/100] 1 tree, 12 leaves, max depth = 6, in 0.003s\n",
      "[93/100] 1 tree, 10 leaves, max depth = 6, in 0.004s\n",
      "[94/100] 1 tree, 13 leaves, max depth = 6, in 0.003s\n",
      "[95/100] 1 tree, 13 leaves, max depth = 6, in 0.007s\n",
      "[96/100] 1 tree, 7 leaves, max depth = 6, in 0.003s\n",
      "[97/100] 1 tree, 13 leaves, max depth = 6, in 0.003s\n",
      "[98/100] 1 tree, 8 leaves, max depth = 6, in 0.002s\n",
      "[99/100] 1 tree, 14 leaves, max depth = 6, in 0.004s\n",
      "[100/100] 1 tree, 13 leaves, max depth = 6, in 0.003s\n",
      "Fit 100 trees in 0.306 s, (1114 total leaves)\n",
      "Time spent computing histograms: 0.045s\n",
      "Time spent finding best splits:  0.021s\n",
      "Time spent applying splits:      0.044s\n",
      "Time spent predicting:           0.003s\n"
     ]
    }
   ],
   "source": [
    "# Define search space for number of trees in random forest and depth of trees\n",
    "num_trees_min = 31\n",
    "num_trees_max = 64\n",
    "\n",
    "depth_min = 2\n",
    "depth_max = 7\n",
    "\n",
    "parameter_scores = []\n",
    "\n",
    "for num_trees in tqdm(range(num_trees_min, num_trees_max)):\n",
    "\n",
    "    for depth in range(depth_min, depth_max):\n",
    "\n",
    "        # Investigate every subset of explanatory variables\n",
    "        for features in subsets(X.columns):\n",
    "            # First CV split. The 219 refers to the first 3 observations for the 73 districts in the data.\n",
    "            Xtrain = X[:219][features].copy().values\n",
    "            ytrain = y[:219]\n",
    "            Xtest = X[219:292][features].copy().values\n",
    "            ytest = y[219:292]\n",
    "\n",
    "            # Create a RandomForestRegressor with the selected hyperparameters and random state 0.\n",
    "            clf = HistGradientBoostingRegressor(max_leaf_nodes=num_trees, max_depth=depth, random_state=0)\n",
    "\n",
    "            # Fit to the training data\n",
    "            clf.fit(Xtrain, ytrain)\n",
    "\n",
    "            # Make a prediction on the test data\n",
    "            predictions = clf.predict(Xtest)\n",
    "\n",
    "            # Calculate mean absolute error\n",
    "            MAE1 = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "            # Second CV split. The 292 refers to the first 4 observations for the 73 districts in the data.\n",
    "            Xtrain = X[:292][features].copy().values\n",
    "            ytrain = y[:292]\n",
    "            Xtest = X[292:365][features].copy().values\n",
    "            ytest = y[292:365]\n",
    "\n",
    "            # Create a RandomForestRegressor with the selected hyperparameters and random state 0.\n",
    "            clf = HistGradientBoostingRegressor(max_leaf_nodes=num_trees, max_depth=depth, random_state=0)\n",
    "\n",
    "            # Fit to the training data\n",
    "            clf.fit(Xtrain, ytrain)\n",
    "\n",
    "            # Make a prediction on the test data\n",
    "            predictions = clf.predict(Xtest)\n",
    "\n",
    "            # Calculate mean absolute error\n",
    "            MAE2 = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "            # Calculate the mean MAE over the two folds\n",
    "            mean_MAE = (MAE1 + MAE2) / 2\n",
    "\n",
    "            # Store the mean MAE together with the used hyperparameters in list\n",
    "            parameter_scores.append((mean_MAE, num_trees, depth, features))\n",
    "\n",
    "# Sort the models based on score and retrieve the hyperparameters of the best model\n",
    "parameter_scores.sort(key=lambda x: x[0])\n",
    "best_model_score = parameter_scores[0][0]\n",
    "best_model_trees = parameter_scores[0][1]\n",
    "best_model_depth = parameter_scores[0][2]\n",
    "best_model_columns = list(parameter_scores[0][3])\n",
    "\n",
    "'''------------SECTION FINAL EVALUATION--------------'''\n",
    "y = df['next_prevalence'].values\n",
    "X = df[best_model_columns].values\n",
    "\n",
    "# If there is only one explanatory variable, the values need to be reshaped for the model\n",
    "if len(best_model_columns) == 1:\n",
    "    X = X.reshape(-1, 1)\n",
    "\n",
    "# Peform evaluation on full data\n",
    "Xtrain = X[:365]\n",
    "ytrain = y[:365]\n",
    "Xtest = X[365:]\n",
    "ytest = y[365:]\n",
    "\n",
    "clf = HistGradientBoostingRegressor(max_leaf_nodes=best_model_trees, max_depth=best_model_depth, random_state=0, verbose=1)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "predictions = clf.predict(Xtest)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate\n",
    "These metrics are incorrect. Check `Histogram Gradient Boosting Evaluation.ipynb` instead."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(291, 291)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate MAE\n",
    "y_true = pd.Series(ytest[:-73]).drop([55,59],axis=0)\n",
    "y_pred = pd.Series(predictions[:-73]).drop([55,59],axis=0)\n",
    "#MAE = mean_absolute_error(ytest, predictions)\n",
    "MAE = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Generate boolean values for increase or decrease in prevalence. 0 if next prevalence is smaller than current prevalence, 1 otherwise.\n",
    "increase = np.where(df.iloc[365:][\"next_prevalence\"] < df.iloc[365:][\"GAM Prevalence\"],0,1)\n",
    "predicted_increase = np.where(predictions < df.iloc[365:][\"GAM Prevalence\"],0,1)\n",
    "\n",
    "len(increase), len(predicted_increase)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of leaves: 31\n",
      "max_depth: 6\n",
      "columns: ['GAM Prevalence', 'SAM Prevalence', 'phase3plus_perc_x', 'rainfall', 'ndvi_score', 'Price of water', 'Total alarms', 'n_conflict_total', 'Average of centy', 'Average of centx', 'prevalence_6lag', 'month', 'increase_numeric']\n",
      "MAE: 0.0211, Accuracy: 73.5%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy of predicted boolean increase/decrease\n",
    "acc = accuracy_score(increase, predicted_increase)\n",
    "\n",
    "# Print model parameters\n",
    "print('no. of leaves: ' + str(best_model_trees) + '\\nmax_depth: ' + str(best_model_depth) + '\\ncolumns: ' + str(\n",
    "    best_model_columns))\n",
    "\n",
    "# Print model scores\n",
    "print(f\"MAE: {np.round(MAE,4)}, Accuracy: {np.round(acc,3)*100}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 73.53951890034365,\n 'precision': 0.7749526732045782,\n 'recall': 0.7353951890034365,\n 'f1': 0.7373683325310192}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_results(y_true=increase, y_pred=predicted_increase)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_confusion_matrix(y_true=increase, y_pred=predicted_increase,classes=[\"Increase\", \"Decrease\"],title=\"Confusion Matrix for Histogram Gradient Boosting Model\", cmap=plt.cm.Purples, figsize=(8,8))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
