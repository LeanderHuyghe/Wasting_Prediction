{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from helper_metrics import count_missing_district, count_missing_district_total, make_confusion_matrix, calculate_results\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.experimental    import enable_iterative_imputer\n",
    "from sklearn.impute          import IterativeImputer\n",
    "from sklearn.experimental    import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble        import HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics         import mean_absolute_error, accuracy_score\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0        date     district  total population  \\\n0             0  2017-07-01  Adan Yabaal       65262.96000   \n1             1  2017-07-01         Luuq      100476.76500   \n2             2  2017-07-01  Buur Hakaba      165968.46000   \n3             3  2017-07-01        Marka      282222.76500   \n4             4  2017-07-01    Buuhoodle       71317.71000   \n..          ...         ...          ...               ...   \n651         671  2021-07-01  Belet Xaawo               NaN   \n652         672  2021-07-01        Jilib               NaN   \n653         674  2021-07-01      Caynabo               NaN   \n654         675  2021-07-01   Rab Dhuure               NaN   \n655         676  2021-07-01      Baraawe               NaN   \n\n     Under-Five Population         GAM         MAM        SAM  GAM Prevalence  \\\n0              13052.59200  4819.01697  3733.04131 1085.97565         0.36920   \n1              20095.35300  8673.15435  7366.95641 1306.19795         0.43160   \n2              33193.69200 11909.89669  8198.84192 3711.05477         0.35880   \n3              56444.55300 20839.32897 16143.14216 4696.18681         0.36920   \n4              14263.54200  4858.16241  3652.89311 1205.26930         0.34060   \n..                     ...         ...         ...        ...             ...   \n651            29314.59999  9820.00000         NaN 1310.00000         0.33499   \n652            28586.09073 11560.00000         NaN 2770.00000         0.40439   \n653            16276.00000  3540.00000         NaN  270.00000         0.21750   \n654            15127.60000  6940.00000         NaN 1560.00000         0.45876   \n655            10954.96873  5100.00000         NaN 1060.00000         0.46554   \n\n     SAM Prevalence  ...  prevalence_6lag  next_prevalence  month  increase  \\\n0           0.08320  ...              NaN          0.35100      7     False   \n1           0.06500  ...              NaN          0.39260      7     False   \n2           0.11180  ...              NaN          0.28860      7     False   \n3           0.08320  ...              NaN          0.35100      7     False   \n4           0.08450  ...              NaN          0.20280      7     False   \n..              ...  ...              ...              ...    ...       ...   \n651         0.04469  ...          0.38353              NaN      7       NaN   \n652         0.09690  ...          0.31242              NaN      7       NaN   \n653         0.01659  ...          0.25746              NaN      7       NaN   \n654         0.10312  ...          0.50720              NaN      7       NaN   \n655         0.09676  ...          0.49119              NaN      7       NaN   \n\n     increase_numeric  district_encoded    Cowpea     Maize  Sorghum      crop  \n0            -0.01820                 0       NaN       NaN      NaN       NaN  \n1            -0.03900                59  14.00000 750.00000 30.00000 264.66667  \n2            -0.07020                24 218.00000  30.00000  1.90000  83.30000  \n3            -0.01820                60 330.00000   6.75000      NaN       NaN  \n4            -0.13780                23       NaN       NaN      NaN       NaN  \n..                ...               ...       ...       ...      ...       ...  \n651               NaN                15   8.00000  50.00000      NaN       NaN  \n652               NaN                51  64.00000 292.00000      NaN       NaN  \n653               NaN                29       NaN       NaN      NaN       NaN  \n654               NaN                66       NaN       NaN 14.00000       NaN  \n655               NaN                11  60.00000 400.00000      NaN       NaN  \n\n[656 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>date</th>\n      <th>district</th>\n      <th>total population</th>\n      <th>Under-Five Population</th>\n      <th>GAM</th>\n      <th>MAM</th>\n      <th>SAM</th>\n      <th>GAM Prevalence</th>\n      <th>SAM Prevalence</th>\n      <th>...</th>\n      <th>prevalence_6lag</th>\n      <th>next_prevalence</th>\n      <th>month</th>\n      <th>increase</th>\n      <th>increase_numeric</th>\n      <th>district_encoded</th>\n      <th>Cowpea</th>\n      <th>Maize</th>\n      <th>Sorghum</th>\n      <th>crop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2017-07-01</td>\n      <td>Adan Yabaal</td>\n      <td>65262.96000</td>\n      <td>13052.59200</td>\n      <td>4819.01697</td>\n      <td>3733.04131</td>\n      <td>1085.97565</td>\n      <td>0.36920</td>\n      <td>0.08320</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.35100</td>\n      <td>7</td>\n      <td>False</td>\n      <td>-0.01820</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2017-07-01</td>\n      <td>Luuq</td>\n      <td>100476.76500</td>\n      <td>20095.35300</td>\n      <td>8673.15435</td>\n      <td>7366.95641</td>\n      <td>1306.19795</td>\n      <td>0.43160</td>\n      <td>0.06500</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.39260</td>\n      <td>7</td>\n      <td>False</td>\n      <td>-0.03900</td>\n      <td>59</td>\n      <td>14.00000</td>\n      <td>750.00000</td>\n      <td>30.00000</td>\n      <td>264.66667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2017-07-01</td>\n      <td>Buur Hakaba</td>\n      <td>165968.46000</td>\n      <td>33193.69200</td>\n      <td>11909.89669</td>\n      <td>8198.84192</td>\n      <td>3711.05477</td>\n      <td>0.35880</td>\n      <td>0.11180</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.28860</td>\n      <td>7</td>\n      <td>False</td>\n      <td>-0.07020</td>\n      <td>24</td>\n      <td>218.00000</td>\n      <td>30.00000</td>\n      <td>1.90000</td>\n      <td>83.30000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2017-07-01</td>\n      <td>Marka</td>\n      <td>282222.76500</td>\n      <td>56444.55300</td>\n      <td>20839.32897</td>\n      <td>16143.14216</td>\n      <td>4696.18681</td>\n      <td>0.36920</td>\n      <td>0.08320</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.35100</td>\n      <td>7</td>\n      <td>False</td>\n      <td>-0.01820</td>\n      <td>60</td>\n      <td>330.00000</td>\n      <td>6.75000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2017-07-01</td>\n      <td>Buuhoodle</td>\n      <td>71317.71000</td>\n      <td>14263.54200</td>\n      <td>4858.16241</td>\n      <td>3652.89311</td>\n      <td>1205.26930</td>\n      <td>0.34060</td>\n      <td>0.08450</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.20280</td>\n      <td>7</td>\n      <td>False</td>\n      <td>-0.13780</td>\n      <td>23</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>651</th>\n      <td>671</td>\n      <td>2021-07-01</td>\n      <td>Belet Xaawo</td>\n      <td>NaN</td>\n      <td>29314.59999</td>\n      <td>9820.00000</td>\n      <td>NaN</td>\n      <td>1310.00000</td>\n      <td>0.33499</td>\n      <td>0.04469</td>\n      <td>...</td>\n      <td>0.38353</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15</td>\n      <td>8.00000</td>\n      <td>50.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>652</th>\n      <td>672</td>\n      <td>2021-07-01</td>\n      <td>Jilib</td>\n      <td>NaN</td>\n      <td>28586.09073</td>\n      <td>11560.00000</td>\n      <td>NaN</td>\n      <td>2770.00000</td>\n      <td>0.40439</td>\n      <td>0.09690</td>\n      <td>...</td>\n      <td>0.31242</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>51</td>\n      <td>64.00000</td>\n      <td>292.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>653</th>\n      <td>674</td>\n      <td>2021-07-01</td>\n      <td>Caynabo</td>\n      <td>NaN</td>\n      <td>16276.00000</td>\n      <td>3540.00000</td>\n      <td>NaN</td>\n      <td>270.00000</td>\n      <td>0.21750</td>\n      <td>0.01659</td>\n      <td>...</td>\n      <td>0.25746</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>654</th>\n      <td>675</td>\n      <td>2021-07-01</td>\n      <td>Rab Dhuure</td>\n      <td>NaN</td>\n      <td>15127.60000</td>\n      <td>6940.00000</td>\n      <td>NaN</td>\n      <td>1560.00000</td>\n      <td>0.45876</td>\n      <td>0.10312</td>\n      <td>...</td>\n      <td>0.50720</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>66</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.00000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>655</th>\n      <td>676</td>\n      <td>2021-07-01</td>\n      <td>Baraawe</td>\n      <td>NaN</td>\n      <td>10954.96873</td>\n      <td>5100.00000</td>\n      <td>NaN</td>\n      <td>1060.00000</td>\n      <td>0.46554</td>\n      <td>0.09676</td>\n      <td>...</td>\n      <td>0.49119</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n      <td>60.00000</td>\n      <td>400.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>656 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/semiyearly_chosen_columns_with_crop.csv\").iloc[:,1:]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create train and test sets\n",
    "X does not need to drop nan values as HGBR can handle nan inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "y = df.next_prevalence.dropna()\n",
    "X = df.select_dtypes(exclude=[\"object\", \"category\"]).iloc[:len(y)].drop([\"next_prevalence\", \"Unnamed: 0\"], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Subsets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Function that returns every possible subset (except the empty set) of the input list l\n",
    "def subsets(l: object) -> object:\n",
    "    subset_list = []\n",
    "    for i in range(len(l) + 1):\n",
    "        for j in range(i):\n",
    "            subset_list.append(l[j: i])\n",
    "    return subset_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross Validation Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "365"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "73*5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 30/33 [5:13:39<27:37, 552.60s/it]  "
     ]
    }
   ],
   "source": [
    "# Define search space for number of trees in random forest and depth of trees\n",
    "num_trees_min = 31\n",
    "num_trees_max = 64\n",
    "\n",
    "depth_min = 2\n",
    "depth_max = 7\n",
    "\n",
    "parameter_scores = []\n",
    "\n",
    "for num_trees in tqdm(range(num_trees_min, num_trees_max)):\n",
    "\n",
    "    for depth in range(depth_min, depth_max):\n",
    "\n",
    "        # Investigate every subset of explanatory variables\n",
    "        for features in subsets(X.columns):\n",
    "            # First CV split. The 222 refers to the first 3 observations for the 74 districts in the data.\n",
    "            Xtrain = X[:222][features].copy().values\n",
    "            ytrain = y[:222]\n",
    "            Xtest = X[222:296][features].copy().values\n",
    "            ytest = y[222:296]\n",
    "\n",
    "            # Create a RandomForestRegressor with the selected hyperparameters and random state 0.\n",
    "            clf = HistGradientBoostingRegressor(max_leaf_nodes=num_trees, max_depth=depth, random_state=0)\n",
    "\n",
    "            # Fit to the training data\n",
    "            clf.fit(Xtrain, ytrain)\n",
    "\n",
    "            # Make a prediction on the test data\n",
    "            predictions = clf.predict(Xtest)\n",
    "\n",
    "            # Calculate mean absolute error\n",
    "            MAE1 = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "            # Second CV split. The 296 refers to the first 4 observations for the 74 districts in the data.\n",
    "            Xtrain = X[:296][features].copy().values\n",
    "            ytrain = y[:296]\n",
    "            Xtest = X[296:370][features].copy().values\n",
    "            ytest = y[296:370]\n",
    "\n",
    "            # Create a RandomForestRegressor with the selected hyperparameters and random state 0.\n",
    "            clf = HistGradientBoostingRegressor(max_leaf_nodes=num_trees, max_depth=depth, random_state=0)\n",
    "\n",
    "            # Fit to the training data\n",
    "            clf.fit(Xtrain, ytrain)\n",
    "\n",
    "            # Make a prediction on the test data\n",
    "            predictions = clf.predict(Xtest)\n",
    "\n",
    "            # Calculate mean absolute error\n",
    "            MAE2 = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "            # Calculate the mean MAE over the two folds\n",
    "            mean_MAE = (MAE1 + MAE2) / 2\n",
    "\n",
    "            # Store the mean MAE together with the used hyperparameters in list\n",
    "            parameter_scores.append((mean_MAE, num_trees, depth, features))\n",
    "\n",
    "# Sort the models based on score and retrieve the hyperparameters of the best model\n",
    "parameter_scores.sort(key=lambda x: x[0])\n",
    "best_model_score = parameter_scores[0][0]\n",
    "best_model_trees = parameter_scores[0][1]\n",
    "best_model_depth = parameter_scores[0][2]\n",
    "best_model_columns = list(parameter_scores[0][3])\n",
    "\n",
    "'''------------SECTION FINAL EVALUATION--------------'''\n",
    "y = df['next_prevalence'].values\n",
    "X = df[best_model_columns].values\n",
    "\n",
    "# If there is only one explanatory variable, the values need to be reshaped for the model\n",
    "if len(best_model_columns) == 1:\n",
    "    X = X.reshape(-1, 1)\n",
    "\n",
    "# Peform evaluation on full data\n",
    "Xtrain = X[:370]\n",
    "ytrain = y[:370]\n",
    "Xtest = X[370:]\n",
    "ytest = y[370:]\n",
    "\n",
    "clf = HistGradientBoostingRegressor(max_leaf_nodes=best_model_trees, max_depth=best_model_depth, random_state=0, verbose=1)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "predictions = clf.predict(Xtest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model_columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = 'crop_model_with_missings.sav'\n",
    "joblib.dump(clf, filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate\n",
    "These metrics are incorrect. Check `Histogram Gradient Boosting Evaluation.ipynb` instead."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate MAE\n",
    "y_true = pd.Series(ytest[:-73]).drop(69)\n",
    "y_pred = pd.Series(predictions[:-73]).drop(69)\n",
    "#MAE = mean_absolute_error(ytest, predictions)\n",
    "MAE = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Generate boolean values for increase or decrease in prevalence. 0 if next prevalence is smaller than current prevalence, 1 otherwise.\n",
    "increase = np.where(df.iloc[365:][\"next_prevalence\"] < df.iloc[365:][\"GAM Prevalence\"],0,1)\n",
    "predicted_increase = np.where(predictions < df.iloc[365:][\"GAM Prevalence\"],0,1)\n",
    "\n",
    "len(increase), len(predicted_increase)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate accuracy of predicted boolean increase/decrease\n",
    "acc = accuracy_score(increase, predicted_increase)\n",
    "\n",
    "# Print model parameters\n",
    "print('no. of leaves: ' + str(best_model_trees) + '\\nmax_depth: ' + str(best_model_depth) + '\\ncolumns: ' + str(\n",
    "    best_model_columns))\n",
    "\n",
    "# Print model scores\n",
    "print(MAE, acc)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}